import requests
import re
import urllib.parse
from bs4 import BeautifulSoup

class Scanner:
    def __init__(self, url, ignore_links):
        self.session = requests.Session()  # Manage login session
        self.target_url = url
        self.target_links = []
        self.links_to_ignore = ignore_links

    def extract_links_from(self, url):
        response = self.session.get(url)
        return re.findall('(?:href=")(.*?)"', str(response.content))

    def crawl(self, url=None):

        if url is None:
            url = self.target_url

        href_links = self.extract_links_from(url)
        for link in href_links:
            link = urllib.parse.urljoin(url, link)

            if '#' in link:
                link = link.split('#')[0]  # store only the first split part

            if self.target_url in link and link not in self.target_links and link not in self.links_to_ignore:
                self.target_links.append(link)
                print(link)
                self.crawl(link)  # Doing it recursively

    def extract_forms(self, url):
        response = self.session.get(url)
        parsed_html = BeautifulSoup(response.content)  # Make the HTML content as object
        return parsed_html.findAll("form")

    def submit_form(self, form, value, url):
        action = form.get("action")  # get form action link
        post_url = urllib.parse.urljoin(url, action)
        method = form.get("method")  # get form method type

        inputs_list = form.findAll("input")  # get all form inputs
        post_data = {}
        for input in inputs_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value")

            if input_type == "text":
                input_value = value

            post_data[input_name] = input_value

            if method == "POST":
                return self.sessions.post(post_url, data=post_data)

            return self.session.get(post_url, params=post_data)
